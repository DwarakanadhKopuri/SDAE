{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "\n",
    "tmp = np.load('/home/konda/workspace/Research/cifar_pca_train.npz')\n",
    "train_data = tmp['data']\n",
    "train_labels = tmp['labels']\n",
    "\n",
    "tmp = np.load('/home/konda/workspace/Research/cifar_pca_test.npz')\n",
    "test_data = tmp['data']\n",
    "test_labels = tmp['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training an autoencoder model on cifar-10 PCA reduced data\n",
    "\n",
    "input_img = Input(shape=(781,))\n",
    "crrpt_img = Dropout(0.5)(input_img)\n",
    "encoded = Dense(1000, activation='sigmoid')(crrpt_img)\n",
    "decoded = Dense(781, activation='linear')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img,decoded)\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_data, train_data,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_data, test_data),\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "autoencoder.save('DAE_l1_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_img,encoded)\n",
    "htrain_data = encoder.predict(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img1 = Input(shape=(1000,))\n",
    "crrpt_img1 = Dropout(0.5)(input_img1)\n",
    "encoded1 = Dense(1000, activation='sigmoid')(crrpt_img1)\n",
    "decoded1 = Dense(1000, activation='sigmoid')(encoded1)\n",
    "\n",
    "autoencoder1 = Model(input_img1,decoded1)\n",
    "\n",
    "autoencoder1.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = autoencoder1.fit(htrain_data, htrain_data,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "autoencoder1.save('DAE_l2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting labels into one-hot vectors for MLP training\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training a simple one hidden layer MLP for classification task\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dropout(0.2, input_shape=(781,)))\n",
    "mlp.add(Dense(1000, activation='sigmoid'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(1000, activation='sigmoid'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = mlp.fit(train_data[:10000], train_labels[:10000],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training with unsupervised initialization for layer-1 \n",
    "# of an MLP using autoencoder weights\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dropout(0.2, input_shape=(781,)))\n",
    "mlp.add(Dense(1000, activation='sigmoid'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(1000, activation='sigmoid'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp.layers[1].set_weights(autoencoder.layers[2].get_weights())\n",
    "mlp.layers[3].set_weights(autoencoder1.layers[2].get_weights())\n",
    "\n",
    "\n",
    "history = mlp.fit(train_data[:10000], train_labels[:10000],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
